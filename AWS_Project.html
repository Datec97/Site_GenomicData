<!DOCTYPE html>
<!-- saved from url=(0035)https://pry-1.netlify.app/#servicio -->
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />

  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>AWS_Project</title>
  <!--Recuerda:
    1.- al colocar librerias deben ponerse primero para que se cargue primero en el navgador
    2.- Dejar el stylesheet personalizado al final
    -->
  <!--
    <link rel="preload" href="./Diseñador Freelancer_files/normalize.css" as="style">
    <link rel="stylesheet" href="./Diseñador Freelancer_files/normalize.css">
    -->
  <!--Ayuda a mejorar el rendimiento de la carga de la pagina web-->
  <link rel="preload" href="./Diseñador Freelancer_files/proyecto1.css" as="style" />
  <link rel="stylesheet" href="./Diseñador Freelancer_files/proyecto1.css" />

  <link rel="preconnect" href="https://fonts.gstatic.com/" />
  <link href="./Diseñador Freelancer_files/css2" rel="stylesheet" />
  <!-- <link href="https://fonts.googleapis.com/css2?family=Courgette&display=swap" rel="stylesheet"> -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.3/font/bootstrap-icons.min.css">

</head>

<body>
  <div class="contenedor_nav">
  </div>
  <!-- encabezado -->
  <section class="heroe" style="background-image: url('img/cad_biomol.jpg')">
    <div class="container-heroe">
      <h2>ETL para el analisis de moléculas bioactivas e información genómica</h2>
      <div class="ubicacion">
        <!--Pegamos el icono vector-->
        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-map-pin" width="68" height="68"
          viewBox="0 0 24 24" stroke-width="2" stroke="#ffbf00" fill="none" stroke-linecap="round"
          stroke-linejoin="round">
          <path stroke="none" d="M0 0h24v24H0z" fill="none"></path>
          <circle cx="12" cy="11" r="3"></circle>
          <path d="M17.657 16.657l-4.243 4.243a2 2 0 0 1 -2.827 0l-4.244 -4.243a8 8 0 1 1 11.314 0z"></path>
        </svg>
        <p>Comas, Lima</p>
      </div>
      <div class="socialNetwork">
        <a href="https://www.linkedin.com/in/oscar-alexis-cisneros-corzo"><i class="bi bi-linkedin"></i></a>
        <a href="https://github.com/Datec97" target="_blank"><i class="bi bi-github"></i></a>
        <a href="https://stackoverflow.com/users/23214679/alexis-008"><i class="bi bi-stack-overflow"></i></a>
      </div>
      </div>
  </section>


  <!--cuerpo-->
  <main class="sombra" id="nos">
      <h2>Desarrollo del proyecto en AWS</h2>

      <!-- salto de linea -->
      <br />
      <div class="responsive_contenido">
<!--          
        <div class="acomode_p" style="margin-top:-10rem">
          <pre>
            <b>Descripción: </b>
            Este dataset, es extraida desde la base de datos ChEMBL, la cual se trata de una base de datos
            que contiene información sobre moléculas bioactivas o información genómica que le permite a 
            científicos e investigadores poder crear fármacos efectivos. Esta base de datos recopila información
            química, de bioactividad y genómica para facilitar la traducción de datos genómicos en nuevos fármacos
            efectivos.
          </pre>
        </div>
-->
      <p>
        <b>Descripción: </b>
        <br>
        <br>
          Este dataset, es extraida desde la base de datos ChEMBL, la cual se trata de una base de datos
          que contiene información sobre moléculas bioactivas o información genómica que le permite a 
          científicos e investigadores poder crear fármacos efectivos. Esta base de datos recopila información
          química, de bioactividad y genómica para facilitar la traducción de datos genómicos en nuevos fármacos
          efectivos.
      </p>
          <p>
            <b>Objetivo:</b>
            Para este dataset, se pretende realizar un procesamiento y limpieza, con apoyo de la herramienta 
            AWS Glue Data Brew.
            <br>
            <br>
            <b>Diseño lógico de la solución cloud:</b>
          </p>
        <figure>
          <a href="img/aws_sol.jpg" target="_blank" class="Click_zoom">
            <img src="img/aws_sol.jpg">
          </a>
        </figure>
        <p>

            <b>Etapa de configuración de nube AWS:</b>
        
            <li>En primera instancia se generan las credenciales de usuario root en IAM , configurando
            un MFA y usuario administrativo en IAM identity center con un MFA diferente.</li>
                <br>
            <li>Configuramos también la herramienta de AWS CLI para su comunicación con el sistema operativo,
            de esta forma poder gestionar los servicios de AWS desde el command line, configurar 
            credenciales y permisos de usuarios AWS.</li>
            <br>
            <p>
            Ahora al generar un usuario IAM (Indentity and Access management) desde la cuenta root creada para
            fines de cumplir con políticas de seguridad AWS y evitar configuraciones malintencionadas, también
            aprovechar la gestión y control de los roles y permisos asignados en cada servicio.
            </p>
        </p>

        <figure>
          <a href="img/cnsl_1.png" target="_blank" class="Click_zoom">
            <img src="img/cnsl_1.png" >
          </a>
        </figure>

        <p>
          Nótese:
          Esta cuenta ha sido creada y configurada bajo el grupo ‘admin_dv’ y dispone de hasta 6 roles,
          incluyendo el acceso al servicio de AWS Glue Databrew para efectos del procesado de la data
        </p>

        <figure>
          <a href="img/cnsl_2.png" target="_blank" class="Click_zoom">
            <img src="img/cnsl_2.png">
          </a>
        </figure>
        
        <p>
          El inicio de sesión a la consola y trabajo del proyecto entonces será desde la cuenta 
          ‘dev_alexis’. Acto siguiente, procedemos a localizar el servicio Glue DataBrew y usar 
          la BD en mención
        </p>
        
        <figure>
          <a href="img/cnsl_3.png" target="_blank" class="Click_zoom">
            <img src="img/cnsl_3.png">
          </a>
        </figure>
    </div>
  </main>

  <main class="sombra" id="nos">
    <div class="responsive_contenido">
        <p>
          A simple vista, podemos ver que inicialmente tenemos 39 columnas y 500 registros o 
          filas en la tabla.

          Dado que no vamos a hacer uso del campo <i>“TID-FIXED”</i>, procedemos a elegir la herramienta
          COLUMN eliminarlo y este proceso se adjunta a la receta de Limpieza/transformación que se debe
          publicar luego.
        
          Acto siguiente, bajo una condición de FILTER, procedemos a eliminar todo aquel registro del 
          campo <i>“CONFIDENCE-SCORE”</i>, cuya magnitud sea menor o igual que 7
        </p>
        
        <figure>
          <a href="img/cnsl_4.png" target="_blank" class="Click_zoom">
            <img src="img/cnsl_4.png">
          </a>
        </figure>

        <p>
          De esta forma, quedamos solo con 119 filas y 38 columnas.
        </p>
        <p>
          Revisando la data, podemos apreciar que existen demasiados “nulls” para el campo <i>"ASAP_TEST_TYPE"</i>
          y <i>"ASSAY_CATEGORY"</i> lo que va implicar que se deban rellenar con algún valor especifico, nos apoyamos
          entonces de MISSING
        </p>

        <figure>
          <a href="img/cnsl_5.png" target="_blank" class="Click_zoom">
            <img src="img/cnsl_5.png">
          </a>
        </figure>
        
        <p>
          Procedemos a publicar nuestra receta de ETL, para futuros tratamientos de otros dataset:
          Sección “recipe”, luego “publish”
        </p>

        <figure>
          <a href="img/cnsl_7.png" target="_blank" class="Click_zoom">
            <img src="img/cnsl_7.png">
          </a>
        </figure>

        <p>
          <b>Configuración del Bucket del servicio Amazon S3</b>
          <br>
          <br>
          Este servicio, esta diseñado para alojar todo tipo de datos, posee una capacidad limitado en el plan gratuito. 
          Por otro lado, se posiciona en el mercado como uno de los principales lideres en su categoria
          Para esto contamos con las siguientes características a configurar:
        </p>
           <figure>
            <img src="img/s3.png" style=" margin-left: 6rem;margin-top: -2rem; height: 40rem; width: 80rem;"></figure>
          </figure>

          <li>Nombre único, sin caracteres especiales </li> 
          <li>Configuramos región, para el caso es US East (Ohio) us-east-2</li> 
          <li>Habilitamos encriptación del lado del servidor.</li>
          <li>Capacidad para 300 objetos</li>
          <p>
              Procedemos ahora a crear trabajo en el AWS Glue Databrew, configurando las siguientes propiedades:
          </p>
        <p>
    </div>
  </main>

  <main class="sombra" id="nos">
    <div class="responsive_contenido">

        <figure>
          <a href="img/cnsl_9.png" target="_blank" class="Click_zoom">
            <img src="img/cnsl_9.png">
          </a>
        </figure>

        <figure>
          <a href="img/cnsl_8.png" target="_blank" class="Click_zoom">
            <img src="img/cnsl_8.png">
          </a>
        </figure>
        <p>
          En el siguiente esquema, se pueden apreciar  los parametros base que conlleva construir un repositorio
          o Datawarehouse, los 3 principales son: salida de datos, tipo de archivos y tipo de compresión. 
        </p>
        <figure>
          <a href="img/cnsl_11.png" target="_blank" class="Click_zoom">
            <img src="img/cnsl_11.png" >
          </a>
        </figure>
        <p>
          Ya en este último punto, consta del despliegue y ejecución automática del ETL creado, conocido también
          como Scheduler, puede ser posible programarla inclusive. Toda la data que se actualiza, pasa por este 
          dataflow y se aloja en un sistema de almacenamiento para su puesta en producción.
        </p>
        <figure>
          <a href="img/cnsl_13.png" target="_blank" class="Click_zoom">
            <img src="img/cnsl_13.png" >
          </a>
        </figure>
        <p>
          Nota: 
          Podemos validar el actual flujo de procesamiento de datos desde la opción Linage. Dentro, se visualiza el
          esquema lógico que la data sigue, así como los servicios que la soportan. Por ejemplo, se encuentra alojada
          en un bucket (contenedor lógico) de Amazon S3. s3://databrew-public-datasets-us-east-2/chembl-27.parquet
        </p>
        <figure>
          <a href="img/cnsl_14.png" target="_blank" class="Click_zoom">
            <img src="img/cnsl_14.png" >
          </a>
        </figure>
    </div>
  </main>

  <footer>
    <a style="color: black; font-size: 5px;" href="https://www.freepik.es/foto-gratis/diseno-diseno-fondo-naranja-liso-abstracto-estudio-habitacion-plantilla-web-informe-comercial-color-degradado-circulo-suave_16788467.htm#fromView=search&page=1&position=45&uuid=b4ea7676-8b83-46e7-9ba3-2ea7fb327a77">benzoix - Freepik</a>
    <p>Todos los derechos reservados, © Alexis Cisneros</p>
  </footer>

  <!-- script aqui dado q si lo colocamos en el head puede que no 
        reconozca el body-->
  <script src="./Diseñador Freelancer_files/practiceDOm.js.download"></script>
</body>

</html>